{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57702e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import talib  \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'SPY']#FAANG portfolio with SPY for market proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f747ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, tickers,):\n",
    "        self.tickers = tickers\n",
    "        self.data = None\n",
    "        \n",
    "    def run_pipeline(self, start_date='2015-01-01', end_date='2024-12-31'):\n",
    "        self._download_data(start_date, end_date)\n",
    "        self._clean_data()\n",
    "        self._validate_data()\n",
    "        return self.data\n",
    "    \n",
    "    def _download_data(self, start_date, end_date):\n",
    "        all_data = []\n",
    "        \n",
    "        for ticker in self.tickers:\n",
    "            \n",
    "            # Download with adjusted close prices and make column names lower\n",
    "            df = yf.download(ticker, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "            \n",
    "            if isinstance(df.columns, pd.MultiIndex): \n",
    "                df.columns = [col[0].lower() for col in df.columns]\n",
    "            else:\n",
    "                df.columns = [col.lower() for col in df.columns]\n",
    "            \n",
    "            df.index.names = [name.lower() if name else 'date' for name in df.index.names]\n",
    "            \n",
    "            df = df[['open', 'high', 'low', 'close', 'volume']] # Keep only essential columns\n",
    "            \n",
    "            df['ticker'] = ticker # Add ticker column and set multi-index, organize data\n",
    "            df = df.reset_index()\n",
    "            df.set_index(['ticker', 'date'], inplace=True)\n",
    "            \n",
    "            all_data.append(df)\n",
    "        \n",
    "        self.data = pd.concat(all_data, axis=0).sort_index()\n",
    "\n",
    "    def _clean_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"No data to clean!\")\n",
    "        \n",
    "        # 1. Fill small gaps (forward fill then backward fill)\n",
    "        self.data = self.data.groupby(level=0, group_keys=False).apply(lambda x: x.ffill().bfill())\n",
    "        \n",
    "        # 2. Drop any remaining NaN (usually at the beginning)\n",
    "        self.data = self.data.dropna()\n",
    "\n",
    "    def _validate_data(self):\n",
    "        # Check date alignment\n",
    "        date_counts = {}\n",
    "        for ticker in self.data.index.get_level_values(0).unique():\n",
    "            dates = self.data.xs(ticker, level=0).index\n",
    "            date_counts[ticker] = len(dates)\n",
    "        \n",
    "        if len(set(date_counts.values())) == 1:\n",
    "            print(f\"All tickers have {list(date_counts.values())[0]} trading days\")\n",
    "        else:\n",
    "            print(\"tickers have different dates\")\n",
    "\n",
    "# Create an instance and run the pipeline\n",
    "preprocessor = DataPreprocessor(tickers)\n",
    "data = preprocessor.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.finished_features = []\n",
    "        \n",
    "    def run_pipeline(self):\n",
    "        self.core_price_features()\n",
    "        self.math_rule_features()\n",
    "        self.momentum_features()\n",
    "        self.volatility_features()\n",
    "        self.volume_features()\n",
    "        self.lagged_features()\n",
    "        self.target_variable()\n",
    "        return self.data\n",
    "    \n",
    "    def _apply_by_ticker(self, func):\n",
    "        return self.data.groupby(level='ticker', group_keys=False).apply(func)\n",
    "    \n",
    "    def core_price_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low, open_ = df['close'], df['high'], df['low'], df['open']\n",
    "            \n",
    "            # Returns\n",
    "            df['log_return'] = np.log(close / close.shift(1))\n",
    "            df['overnight_return'] = np.log(open_ / close.shift(1))\n",
    "            df['intraday_return'] = np.log(close / open_)\n",
    "            # Volatility\n",
    "            df['volatility_20d'] = df['log_return'].rolling(20).std() * np.sqrt(252)\n",
    "            df['atr_14'] = talib.ATR(high, low, close, timeperiod=14)\n",
    "            # SMAs\n",
    "            sma10 = talib.SMA(close, timeperiod=10)\n",
    "            sma20 = talib.SMA(close, timeperiod=20)\n",
    "            sma50 = talib.SMA(close, timeperiod=50)\n",
    "            #ratios\n",
    "            df['price_sma20_ratio'] = close / sma20\n",
    "            df['price_sma50_ratio'] = close / sma50\n",
    "            df['sma10_sma20_ratio'] = sma10 / sma20\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['log_return', 'overnight_return', 'intraday_return', 'volatility_20d', 'atr_14', 'price_sma20_ratio', 'price_sma50_ratio', 'sma10_sma20_ratio']\n",
    "    \n",
    "    def math_rule_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low, volume = df['close'], df['high'], df['low'], df['volume']\n",
    "            \n",
    "            # SMAs\n",
    "            sma10 = talib.SMA(close, timeperiod=10)\n",
    "            sma20 = talib.SMA(close, timeperiod=20)\n",
    "            sma50 = talib.SMA(close, timeperiod=50)\n",
    "            sma200 = talib.SMA(close, timeperiod=200)\n",
    "            \n",
    "            # Trends\n",
    "            df['golden_cross'] = (sma50 > sma200).astype(int)\n",
    "            df['short_uptrend'] = (sma10 > sma20).astype(int)\n",
    "            df['price_above_sma20'] = (close > sma20).astype(int)\n",
    "            df['price_above_sma50'] = (close > sma50).astype(int)\n",
    "            \n",
    "            # Momentum\n",
    "            rsi = talib.RSI(close, timeperiod=14)\n",
    "            macd, signal, _ = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            stoch_k, _ = talib.STOCH(high, low, close, fastk_period=14, slowk_period=3, slowd_period=3)\n",
    "            roc = talib.ROC(close, timeperiod=10)\n",
    "            df['rsi_oversold'] = (rsi < 30).astype(int)\n",
    "            df['rsi_overbought'] = (rsi > 70).astype(int)\n",
    "            df['macd_bullish'] = (macd > signal).astype(int)\n",
    "            df['roc_positive'] = (roc > 0).astype(int)\n",
    "            df['stoch_oversold'] = (stoch_k < 20).astype(int)\n",
    "            \n",
    "            # Volatility/Reversion \n",
    "            upper, _, lower = talib.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "            bb_pos = (close - lower) / (upper - lower)\n",
    "            vol_20d = df['log_return'].rolling(20).std() * np.sqrt(252)\n",
    "            vol_75pct = vol_20d.expanding().quantile(0.75)\n",
    "            df['bb_oversold'] = (bb_pos < 0.2).astype(int)\n",
    "            df['bb_overbought'] = (bb_pos > 0.8).astype(int)\n",
    "            df['high_volatility'] = (vol_20d > vol_75pct).astype(int)\n",
    "            \n",
    "            # Volume \n",
    "            vol_sma20 = talib.SMA(volume, timeperiod=20)\n",
    "            vol_ratio = volume / vol_sma20\n",
    "            price_up = close > close.shift(1)\n",
    "            price_down = close < close.shift(1)\n",
    "            df['volume_spike'] = (vol_ratio > 1.5).astype(int)\n",
    "            df['volume_confirmation'] = (price_up & (vol_ratio > 1)).astype(int)\n",
    "            df['volume_divergence'] = (price_down & (vol_ratio > 1)).astype(int)\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['golden_cross', 'short_uptrend', 'price_above_sma20', 'price_above_sma50','rsi_oversold', 'rsi_overbought', 'macd_bullish', 'roc_positive', 'stoch_oversold','bb_oversold', 'bb_overbought', 'high_volatility','volume_spike', 'volume_confirmation', 'volume_divergence']\n",
    "    \n",
    "    def momentum_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low = df['close'], df['high'], df['low']\n",
    "            \n",
    "            df['rsi_14'] = talib.RSI(close, timeperiod=14)\n",
    "            macd, signal, hist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            df['macd_histogram'] = hist\n",
    "            df['stoch_k'], _ = talib.STOCH(high, low, close, fastk_period=14, slowk_period=3, slowd_period=3)\n",
    "            df['williams_r'] = talib.WILLR(high, low, close, timeperiod=14)\n",
    "            df['roc_10'] = talib.ROC(close, timeperiod=10)\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['rsi_14', 'macd_histogram', 'stoch_k', 'williams_r', 'roc_10']\n",
    "    \n",
    "    def volatility_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low = df['close'], df['high'], df['low']\n",
    "            \n",
    "            upper, middle, lower = talib.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "            df['bb_position'] = (close - lower) / (upper - lower)\n",
    "            df['bb_width'] = (upper - lower) / middle\n",
    "            df['parkinson_vol'] = np.sqrt((1 / (4 * np.log(2))) * (np.log(high / low) ** 2)).rolling(20).mean()\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['bb_position', 'bb_width', 'parkinson_vol',]\n",
    "    \n",
    "    def volume_features(self):\n",
    "        def calc(df):\n",
    "            close, volume = df['close'], df['volume']\n",
    "            \n",
    "            vol_sma20 = talib.SMA(volume, timeperiod=20)\n",
    "            df['volume_ratio'] = volume / vol_sma20\n",
    "            df['obv'] = talib.OBV(close, volume)\n",
    "            df['volume_zscore'] = (volume - volume.rolling(20).mean()) / volume.rolling(20).std()\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['volume_ratio', 'obv', 'volume_zscore']\n",
    "    \n",
    "    def lagged_features(self):\n",
    "        lag_cols = ['log_return', 'rsi_14', 'volume_ratio', 'macd_histogram', 'bb_position', 'atr_14']\n",
    "        \n",
    "        def calc(df):\n",
    "            for col in lag_cols:\n",
    "                df[f'{col}_lag1'] = df[col].shift(1)\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += [f'{col}_lag1' for col in lag_cols]\n",
    "    \n",
    "    def target_variable(self):\n",
    "        def calc(df):\n",
    "            df['target'] = df['log_return'].shift(-1)  # Predict tomorrow's return\n",
    "            return df\n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "\n",
    "\n",
    "fe = FeatureEngineer(data)\n",
    "features_data = fe.run_pipeline()\n",
    "print(f\"Features created: {len(fe.finished_features)}\")\n",
    "print(f\"Data shape: {features_data.shape}\")\n",
    "#features_data.groupby(level='ticker').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedModel:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.binary_features = [\n",
    "            'golden_cross', 'short_uptrend', 'price_above_sma20', 'price_above_sma50','rsi_oversold', 'rsi_overbought', 'macd_bullish', 'roc_positive',\n",
    "            'stoch_oversold','bb_oversold', 'bb_overbought', 'high_volatility','volume_spike', 'volume_confirmation', 'volume_divergence'\n",
    "        ]\n",
    "        # Default weights: positive = bullish signal, negative = bearish signal\n",
    "        self.weights = {\n",
    "            # Trend (bullish)\n",
    "            'golden_cross': 2.0,\n",
    "            'short_uptrend': 1.5,\n",
    "            'price_above_sma20': 1.0,\n",
    "            'price_above_sma50': 1.0,\n",
    "            # Momentum\n",
    "            'rsi_oversold': 1.5,        # Oversold = buy opportunity\n",
    "            'rsi_overbought': -1.5,     # Overbought = sell signal\n",
    "            'macd_bullish': 1.5,\n",
    "            'roc_positive': 1.0,\n",
    "            'stoch_oversold': 1.0,\n",
    "            # Volatility/Reversion\n",
    "            'bb_oversold': 1.5,         # Mean reversion buy\n",
    "            'bb_overbought': -1.5,      # Mean reversion sell\n",
    "            'high_volatility': -0.5,    # High vol = reduce risk\n",
    "            # Volume\n",
    "            'volume_spike': 0.5,\n",
    "            'volume_confirmation': 1.5, # Price up + volume = strong\n",
    "            'volume_divergence': -1.5   # Price down + volume = weak\n",
    "        }\n",
    "        self.results = None\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        self._calculate_scores()\n",
    "        self._generate_signals()\n",
    "    \n",
    "    def _apply_by_ticker(self, func):\n",
    "        return self.data.groupby(level='ticker', group_keys=False).apply(func)\n",
    "    \n",
    "    def _calculate_scores(self):\n",
    "        self.data['rule_score'] = sum(\n",
    "            self.data[feat] * self.weights[feat] for feat in self.binary_features\n",
    "        )\n",
    "        # Normalize to [-1, 1] range\n",
    "        max_pos = sum(w for w in self.weights.values() if w > 0)\n",
    "        max_neg = abs(sum(w for w in self.weights.values() if w < 0))\n",
    "        self.data['rule_score_norm'] = self.data['rule_score'].apply(\n",
    "            lambda x: x / max_pos if x > 0 else x / max_neg if x < 0 else 0\n",
    "        )\n",
    "    \n",
    "    def _generate_signals(self):\n",
    "        # Thresholds for signal generation\n",
    "        long_threshold = 0.3\n",
    "        short_threshold = -0.3\n",
    "        \n",
    "        self.data['signal'] = 0\n",
    "        self.data.loc[self.data['rule_score_norm'] > long_threshold, 'signal'] = 1\n",
    "        self.data.loc[self.data['rule_score_norm'] < short_threshold, 'signal'] = -1\n",
    "        self.data['strategy_return'] = self.data['signal'].shift(1) * self.data['log_return']\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostModel:\n",
    "    def __init__(self, train_data, test_data, feature_cols):\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data.copy()\n",
    "        self.feature_cols = feature_cols\n",
    "        self.model = None\n",
    "        self.results = None\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.n_estimators = 100\n",
    "        self.learning_rate = 0.1\n",
    "        self.max_depth = 3\n",
    "        self.subsample = 0.8\n",
    "        self.colsample_bytree = 0.8\n",
    "        self.threshold = 0.0005  # 0.05% daily return threshold\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        self._train_model()\n",
    "        self._generate_predictions()\n",
    "        self._generate_signals()\n",
    "        self._calculate_returns()\n",
    "    \n",
    "    def _train_model(self):\n",
    "        X_train = self.train_data[self.feature_cols]\n",
    "        y_train = self.train_data['target']\n",
    "        \n",
    "        self.model = xgb.XGBRegressor(\n",
    "            n_estimators=self.n_estimators,\n",
    "            learning_rate=self.learning_rate,\n",
    "            max_depth=self.max_depth,\n",
    "            subsample=self.subsample,\n",
    "            colsample_bytree=self.colsample_bytree,\n",
    "            random_state=42,\n",
    "        )\n",
    "        \n",
    "        self.model.fit(X_train, y_train)\n",
    "    \n",
    "    def _generate_predictions(self):\n",
    "        X_test = self.test_data[self.feature_cols]\n",
    "        self.test_data['xgb_pred'] = self.model.predict(X_test)\n",
    "    \n",
    "    def _generate_signals(self): # convert predictions to trading signals\n",
    "        self.test_data['signal'] = 0\n",
    "        self.test_data.loc[self.test_data['xgb_pred'] > self.threshold, 'signal'] = 1\n",
    "        self.test_data.loc[self.test_data['xgb_pred'] < -self.threshold, 'signal'] = -1\n",
    "    \n",
    "    def _calculate_returns(self):\n",
    "        self.test_data['strategy_return'] = self.test_data['signal'].shift(1) * self.test_data['log_return']\n",
    "\n",
    "# Prepare train/test split\n",
    "feature_cols = fe.finished_features\n",
    "model_df = features_data.dropna(subset=feature_cols + ['target']).copy()\n",
    "train_start = pd.Timestamp('2015-01-01')\n",
    "train_end = pd.Timestamp('2021-01-01')\n",
    "test_start = pd.Timestamp('2022-01-01') \n",
    "test_end = pd.Timestamp('2024-01-01')\n",
    "\n",
    "train_mask = (model_df.index.get_level_values('date') >= train_start) & \\\n",
    "            (model_df.index.get_level_values('date') <= train_end)\n",
    "test_mask = (model_df.index.get_level_values('date') >= test_start) & \\\n",
    "            (model_df.index.get_level_values('date') < test_end)\n",
    "\n",
    "\n",
    "train_data = model_df[train_mask]\n",
    "test_data = model_df[test_mask]\n",
    "rb_model = RuleBasedModel(test_data)\n",
    "rb_model.run_pipeline()\n",
    "xgb_model = XGBoostModel(train_data, test_data, feature_cols)\n",
    "xgb_model.run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53718a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison: XGBoost vs Rule-Based\n",
    "\n",
    "def calculate_metrics(returns_col, signal_col, df):\n",
    "    results = {}\n",
    "    for ticker in df.index.get_level_values('ticker').unique():\n",
    "        ticker_data = df.xs(ticker, level='ticker').dropna(subset=[returns_col, 'log_return'])\n",
    "        if len(ticker_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        strat_ret = ticker_data[returns_col]\n",
    "        buy_hold = ticker_data['log_return']\n",
    "        signals = ticker_data[signal_col]\n",
    "        \n",
    "        # Cumulative returns\n",
    "        strat_cum = np.exp(strat_ret.sum()) - 1\n",
    "        bh_cum = np.exp(buy_hold.sum()) - 1\n",
    "        sharpe = (strat_ret.mean() / strat_ret.std()) * np.sqrt(252) if strat_ret.std() > 0 else 0\n",
    "        \n",
    "        # Max drawdown\n",
    "        cum_log_rets = strat_ret.cumsum()\n",
    "        running_max = cum_log_rets.expanding().max()\n",
    "        drawdown = cum_log_rets - running_max\n",
    "        max_dd = np.exp(drawdown.min()) - 1\n",
    "        \n",
    "        # Win rate\n",
    "        wins = (strat_ret > 0).sum()\n",
    "        trades = (signals != 0).sum()\n",
    "        win_rate = wins / trades if trades > 0 else 0\n",
    "        \n",
    "        results[ticker] = {\n",
    "            'return': strat_cum,\n",
    "            'bh_return': bh_cum,\n",
    "            'sharpe': sharpe,\n",
    "            'max_dd': max_dd,\n",
    "            'win_rate': win_rate,\n",
    "            'trades': trades\n",
    "        }\n",
    "\n",
    "    all_returns = df.dropna(subset=[returns_col])[returns_col]\n",
    "    overall_sharpe = (all_returns.mean() / all_returns.std()) * np.sqrt(252) if all_returns.std() > 0 else 0\n",
    "\n",
    "    return results, overall_sharpe\n",
    "\n",
    "xgb_results, xgb_overall = calculate_metrics('strategy_return', 'signal', xgb_model.test_data)\n",
    "rb_results, rb_overall = calculate_metrics('strategy_return', 'signal', rb_model.data)\n",
    "\n",
    "for ticker in sorted(xgb_results.keys()): #Print results in a table\n",
    "    xgb_metrics = xgb_results[ticker]\n",
    "    rb_metrics = rb_results[ticker]\n",
    "\n",
    "    print(f\"\\n{ticker}:\")\n",
    "    print(f\"  {'Metric':<20} {'XGBoost':>12} {'Rule-Based':>12} {'Difference':>12}\")\n",
    "    print(f\"  {'-'*20} {'-'*12} {'-'*12} {'-'*12}\")\n",
    "    print(f\"  {'Strategy Return':<20} {xgb_metrics['return']*100:>11.2f}% {rb_metrics['return']*100:>11.2f}% {(xgb_metrics['return']-rb_metrics['return'])*100:>11.2f}%\")\n",
    "    print(f\"  {'Buy & Hold':<20} {xgb_metrics['bh_return']*100:>11.2f}% {rb_metrics['bh_return']*100:>11.2f}%\")\n",
    "    print(f\"  {'Sharpe Ratio':<20} {xgb_metrics['sharpe']:>12.2f} {rb_metrics['sharpe']:>12.2f} {xgb_metrics['sharpe']-rb_metrics['sharpe']:>12.2f}\")\n",
    "    print(f\"  {'Max Drawdown':<20} {xgb_metrics['max_dd']*100:>11.2f}% {rb_metrics['max_dd']*100:>11.2f}% {(xgb_metrics['max_dd']-rb_metrics['max_dd'])*100:>11.2f}%\")\n",
    "    print(f\"  {'Win Rate':<20} {xgb_metrics['win_rate']*100:>11.1f}% {rb_metrics['win_rate']*100:>11.1f}% {(xgb_metrics['win_rate']-rb_metrics['win_rate'])*100:>11.1f}%\")\n",
    "    print(f\"  {'Trades':<20} {xgb_metrics['trades']:>12} {rb_metrics['trades']:>12} {xgb_metrics['trades']-rb_metrics['trades']:>12}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"OVERALL SHARPE RATIO:\")\n",
    "print(f\"  XGBoost:    {xgb_overall:>6.3f}\")\n",
    "print(f\"  Rule-Based: {rb_overall:>6.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940eccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization\n",
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'SPY']\n",
    "continued_input = True\n",
    "while continued_input == True:\n",
    "    input_ticker = input(\"Please enter a stock ('AAPL') for example: \" )\n",
    "    for i in range(6):\n",
    "        if input_ticker == tickers[i]:\n",
    "            print(\"Done\")\n",
    "            continued_input = False\n",
    "    \n",
    "graphed_df = rb_model.data.xs(input_ticker, level = 0)\n",
    "\n",
    "strategy_graphed_return_pct = (np.exp(graphed_df['strategy_return'].cumsum()) - 1) * 100\n",
    "\n",
    "dates = graphed_df.index\n",
    "\n",
    "xgb_graphed_cum_return_pct = (\n",
    "    xgb_model.test_data\n",
    "    .groupby(level='ticker')['strategy_return']\n",
    "    .apply(lambda x: (np.exp(x.cumsum()) - 1) * 100)\n",
    ")\n",
    "\n",
    "xgb_graphed_returns = xgb_graphed_cum_return_pct.xs(input_ticker, level = 0)\n",
    "\n",
    "\n",
    "class data_analysis:\n",
    "    line_dict = dict(marker = \".\", markersize = 3)\n",
    "\n",
    "    def __init__(self, x_XGBoost, y_XGBoost, x_RB, y_RB, rb_model):\n",
    "        self.rbmodel = rb_model\n",
    "        print(\"Graphs Based on\", input_ticker, \"Stock\")\n",
    "        \n",
    "        self.xgboost_graph(x_XGBoost, y_XGBoost)\n",
    "        self.rulebased_model_graph(x_RB, y_RB)\n",
    "        self.combined_graph(x_XGBoost, y_XGBoost, x_RB, y_RB)\n",
    "\n",
    "    def xgboost_graph(self, x_XGBoost, y_XGBoost):\n",
    "        plt.title(\"XGBoost Performance Graph\")\n",
    "\n",
    "        plt.xlabel(\"Dates\")\n",
    "        plt.ylabel(\"XGBoost Returns (%)\")\n",
    "        \n",
    "        plt.plot(dates, xgb_graphed_cum_return_pct[:len(dates)], **self.line_dict)\n",
    "        plt.tick_params(axis = 'x', which = 'major', labelsize = 8)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def rulebased_model_graph(self, x_RB, y_RB):\n",
    "        plt.title(\"Rule Based Model Performance Graph\")\n",
    "\n",
    "        plt.xlabel(\"Dates\")\n",
    "        plt.ylabel(\"Rule Based Returns (%)\")\n",
    "        \n",
    "        plt.plot(dates[:len(strategy_graphed_return_pct)], strategy_graphed_return_pct, color='orange', **self.line_dict)\n",
    "        plt.tick_params(axis = 'x', which = 'major', labelsize = 8)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def combined_graph(self, x_XGBoost, y_XGBoost, x_RB, y_RB):\n",
    "        plt.title(\"Combined Performance Graph\")\n",
    "\n",
    "        plt.xlabel(\"Dates\")\n",
    "        plt.ylabel(\"Strategy Returns (%)\")\n",
    "        \n",
    "        plt.plot(dates, xgb_graphed_cum_return_pct[:len(dates)], label='XGBoost', **self.line_dict)\n",
    "        plt.plot(dates[:len(strategy_graphed_return_pct)], strategy_graphed_return_pct, color='orange', label='Rule-Based', **self.line_dict)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tick_params(axis = 'x', which = 'major', labelsize = 8)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "analyse_data = data_analysis(dates, xgb_graphed_cum_return_pct[:len(dates)], dates[:len(strategy_graphed_return_pct)], strategy_graphed_return_pct, rb_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-finance",
   "language": "python",
   "name": "conda-env-anaconda-finance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
