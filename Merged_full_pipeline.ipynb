{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a674c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import talib \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'SPY']#FAANG portfolio with SPY for market proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3ed525f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, tickers,):\n",
    "        self.tickers = tickers\n",
    "        self.data = None\n",
    "        \n",
    "    def run_pipeline(self, start_date='2010-01-01', end_date='2024-12-31'):\n",
    "        self._download_data(start_date, end_date)\n",
    "        self._clean_data()\n",
    "        self._validate_data()\n",
    "        return self.data\n",
    "    \n",
    "    def _download_data(self, start_date, end_date):\n",
    "        all_data = []\n",
    "        \n",
    "        for ticker in self.tickers:\n",
    "            \n",
    "            # Download with adjusted close prices and make column names lower\n",
    "            df = yf.download(ticker, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "            \n",
    "            if isinstance(df.columns, pd.MultiIndex): \n",
    "                df.columns = [col[0].lower() for col in df.columns]\n",
    "            else:\n",
    "                df.columns = [col.lower() for col in df.columns]\n",
    "            \n",
    "            df.index.names = [name.lower() if name else 'date' for name in df.index.names]\n",
    "            \n",
    "            df = df[['open', 'high', 'low', 'close', 'volume']] # Keep only essential columns\n",
    "            \n",
    "            df['ticker'] = ticker # Add ticker column and set multi-index, organize data\n",
    "            df = df.reset_index()\n",
    "            df.set_index(['ticker', 'date'], inplace=True)\n",
    "            \n",
    "            all_data.append(df)\n",
    "        \n",
    "        self.data = pd.concat(all_data, axis=0).sort_index()\n",
    "\n",
    "    def _clean_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"No data to clean!\")\n",
    "        \n",
    "        # CRITICAL FIX: Align all tickers to common trading dates\n",
    "        # 1. Get the intersection of all trading dates (dates where ALL tickers traded)\n",
    "        all_dates = {}\n",
    "        for ticker in self.data.index.get_level_values('ticker').unique():\n",
    "            ticker_data = self.data.xs(ticker, level='ticker')\n",
    "            all_dates[ticker] = set(ticker_data.index)\n",
    "        \n",
    "        # Find common dates across all tickers\n",
    "        common_dates = set.intersection(*all_dates.values())\n",
    "        common_dates = sorted(list(common_dates))\n",
    "        \n",
    "        print(f\"Found {len(common_dates)} common trading days across all tickers\")\n",
    "        \n",
    "        # 2. Filter each ticker to only common dates\n",
    "        aligned_data = []\n",
    "        for ticker in self.data.index.get_level_values('ticker').unique():\n",
    "            ticker_data = self.data.xs(ticker, level='ticker')\n",
    "            ticker_data = ticker_data[ticker_data.index.isin(common_dates)]\n",
    "            ticker_data['ticker'] = ticker\n",
    "            ticker_data = ticker_data.reset_index()\n",
    "            ticker_data.set_index(['ticker', 'date'], inplace=True)\n",
    "            aligned_data.append(ticker_data)\n",
    "        \n",
    "        self.data = pd.concat(aligned_data, axis=0).sort_index()\n",
    "        \n",
    "        # 3. Fill any remaining small gaps within common dates\n",
    "        self.data = self.data.groupby(level='ticker', group_keys=False).apply(lambda x: x.ffill().bfill())\n",
    "        \n",
    "        # 4. Final check - drop any NaN that might remain\n",
    "        initial_shape = self.data.shape[0]\n",
    "        self.data = self.data.dropna()\n",
    "        if self.data.shape[0] < initial_shape:\n",
    "            print(f\"Dropped {initial_shape - self.data.shape[0]} rows with NaN values\")\n",
    "\n",
    "    def _validate_data(self):\n",
    "        # Verify date alignment\n",
    "        date_counts = {}\n",
    "        for ticker in self.data.index.get_level_values('ticker').unique():\n",
    "            dates = self.data.xs(ticker, level='ticker').index\n",
    "            date_counts[ticker] = len(dates)\n",
    "        \n",
    "        if len(set(date_counts.values())) == 1:\n",
    "            print(f\"✓ All tickers aligned: {list(date_counts.values())[0]} trading days each\")\n",
    "        else:\n",
    "            print(f\"✗ ERROR: Tickers have different date counts: {date_counts}\")\n",
    "            raise ValueError(\"Date alignment failed! Cannot proceed with misaligned data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c30a3019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features created: 40\n",
      "Data shape: (19044, 46)\n"
     ]
    }
   ],
   "source": [
    "class FeatureEngineer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.finished_features = []\n",
    "        \n",
    "    def run_pipeline(self):\n",
    "        self.core_price_features()\n",
    "        self.math_rule_features()\n",
    "        self.momentum_features()\n",
    "        self.volatility_features()\n",
    "        self.volume_features()\n",
    "        self.lagged_features()\n",
    "        self.target_variable()\n",
    "        return self.data\n",
    "    \n",
    "    def _apply_by_ticker(self, func):\n",
    "        return self.data.groupby(level='ticker', group_keys=False).apply(func)\n",
    "    \n",
    "    def core_price_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low, open_ = df['close'], df['high'], df['low'], df['open']\n",
    "            \n",
    "            # Returns\n",
    "            df['log_return'] = np.log(close / close.shift(1))\n",
    "            df['overnight_return'] = np.log(open_ / close.shift(1))\n",
    "            df['intraday_return'] = np.log(close / open_)\n",
    "            # Volatility\n",
    "            df['volatility_20d'] = df['log_return'].rolling(20).std() * np.sqrt(252)\n",
    "            df['atr_14'] = talib.ATR(high, low, close, timeperiod=14)\n",
    "            # SMAs\n",
    "            sma10 = talib.SMA(close, timeperiod=10)\n",
    "            sma20 = talib.SMA(close, timeperiod=20)\n",
    "            sma50 = talib.SMA(close, timeperiod=50)\n",
    "            #ratios\n",
    "            df['price_sma20_ratio'] = close / sma20\n",
    "            df['price_sma50_ratio'] = close / sma50\n",
    "            df['sma10_sma20_ratio'] = sma10 / sma20\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['log_return', 'overnight_return', 'intraday_return', 'volatility_20d', 'atr_14', 'price_sma20_ratio', 'price_sma50_ratio', 'sma10_sma20_ratio']\n",
    "    \n",
    "    def math_rule_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low, volume = df['close'], df['high'], df['low'], df['volume']\n",
    "            \n",
    "            # SMAs\n",
    "            sma10 = talib.SMA(close, timeperiod=10)\n",
    "            sma20 = talib.SMA(close, timeperiod=20)\n",
    "            sma50 = talib.SMA(close, timeperiod=50)\n",
    "            sma200 = talib.SMA(close, timeperiod=200)\n",
    "            \n",
    "            # Trends\n",
    "            df['golden_cross'] = (sma50 > sma200).astype(int)\n",
    "            df['short_uptrend'] = (sma10 > sma20).astype(int)\n",
    "            df['price_above_sma20'] = (close > sma20).astype(int)\n",
    "            df['price_above_sma50'] = (close > sma50).astype(int)\n",
    "            \n",
    "            # Momentum\n",
    "            rsi = talib.RSI(close, timeperiod=14)\n",
    "            macd, signal, _ = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            stoch_k, _ = talib.STOCH(high, low, close, fastk_period=14, slowk_period=3, slowd_period=3)\n",
    "            roc = talib.ROC(close, timeperiod=10)\n",
    "            df['rsi_oversold'] = (rsi < 30).astype(int)\n",
    "            df['rsi_overbought'] = (rsi > 70).astype(int)\n",
    "            df['macd_bullish'] = (macd > signal).astype(int)\n",
    "            df['roc_positive'] = (roc > 0).astype(int)\n",
    "            df['stoch_oversold'] = (stoch_k < 20).astype(int)\n",
    "            \n",
    "            # Volatility/Reversion \n",
    "            upper, _, lower = talib.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "            bb_pos = (close - lower) / (upper - lower)\n",
    "            vol_20d = df['log_return'].rolling(20).std() * np.sqrt(252)\n",
    "            vol_75pct = vol_20d.rolling(window=252, min_periods=50).quantile(0.75)  # FIXED: Use rolling instead of expanding\n",
    "            df['bb_oversold'] = (bb_pos < 0.2).astype(int)\n",
    "            df['bb_overbought'] = (bb_pos > 0.8).astype(int)\n",
    "            df['high_volatility'] = (vol_20d > vol_75pct).astype(int)\n",
    "            \n",
    "            # Volume \n",
    "            vol_sma20 = talib.SMA(volume, timeperiod=20)\n",
    "            vol_ratio = volume / vol_sma20\n",
    "            price_up = close > close.shift(1)\n",
    "            price_down = close < close.shift(1)\n",
    "            df['volume_spike'] = (vol_ratio > 1.5).astype(int)\n",
    "            df['volume_confirmation'] = (price_up & (vol_ratio > 1)).astype(int)\n",
    "            df['volume_divergence'] = (price_down & (vol_ratio > 1)).astype(int)\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['golden_cross', 'short_uptrend', 'price_above_sma20', 'price_above_sma50','rsi_oversold', 'rsi_overbought', 'macd_bullish', 'roc_positive', 'stoch_oversold','bb_oversold', 'bb_overbought', 'high_volatility','volume_spike', 'volume_confirmation', 'volume_divergence']\n",
    "    \n",
    "    def momentum_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low = df['close'], df['high'], df['low']\n",
    "            \n",
    "            df['rsi_14'] = talib.RSI(close, timeperiod=14)\n",
    "            macd, signal, hist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            df['macd_histogram'] = hist\n",
    "            df['stoch_k'], _ = talib.STOCH(high, low, close, fastk_period=14, slowk_period=3, slowd_period=3)\n",
    "            df['williams_r'] = talib.WILLR(high, low, close, timeperiod=14)\n",
    "            df['roc_10'] = talib.ROC(close, timeperiod=10)\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['rsi_14', 'macd_histogram', 'stoch_k', 'williams_r', 'roc_10']\n",
    "    \n",
    "    def volatility_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low = df['close'], df['high'], df['low']\n",
    "            \n",
    "            upper, middle, lower = talib.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "            df['bb_position'] = (close - lower) / (upper - lower)\n",
    "            df['bb_width'] = (upper - lower) / middle\n",
    "            df['parkinson_vol'] = np.sqrt((1 / (4 * np.log(2))) * (np.log(high / low) ** 2)).rolling(20).mean()\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['bb_position', 'bb_width', 'parkinson_vol',]\n",
    "    \n",
    "    def volume_features(self):\n",
    "        def calc(df):\n",
    "            close, volume = df['close'], df['volume']\n",
    "            \n",
    "            vol_sma20 = talib.SMA(volume, timeperiod=20)\n",
    "            df['volume_ratio'] = volume / vol_sma20\n",
    "            df['obv'] = talib.OBV(close, volume)\n",
    "            df['volume_zscore'] = (volume - volume.rolling(20).mean()) / volume.rolling(20).std()\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['volume_ratio', 'obv', 'volume_zscore']\n",
    "    \n",
    "    def lagged_features(self):\n",
    "        lag_cols = ['log_return', 'rsi_14', 'volume_ratio', 'macd_histogram', 'bb_position', 'atr_14']\n",
    "        \n",
    "        def calc(df):\n",
    "            for col in lag_cols:\n",
    "                df[f'{col}_lag1'] = df[col].shift(1)\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += [f'{col}_lag1' for col in lag_cols]\n",
    "    \n",
    "    def target_variable(self):\n",
    "        def calc(df):\n",
    "            df['target'] = df['log_return'].shift(-1)  # Predict tomorrow's return\n",
    "            return df\n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "\n",
    "\n",
    "fe = FeatureEngineer(data)\n",
    "features_data = fe.run_pipeline()\n",
    "print(f\"Features created: {len(fe.finished_features)}\")\n",
    "print(f\"Data shape: {features_data.shape}\")\n",
    "#features_data.groupby(level='ticker').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d6432a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedModel:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.binary_features = [\n",
    "            'golden_cross', 'short_uptrend', 'price_above_sma20', 'price_above_sma50','rsi_oversold', 'rsi_overbought', 'macd_bullish', 'roc_positive',\n",
    "            'stoch_oversold','bb_oversold', 'bb_overbought', 'high_volatility','volume_spike', 'volume_confirmation', 'volume_divergence'\n",
    "        ]\n",
    "        # Default weights: positive = bullish signal, negative = bearish signal\n",
    "        self.weights = {\n",
    "            # Trend (bullish)\n",
    "            'golden_cross': 2.0,\n",
    "            'short_uptrend': 1.5,\n",
    "            'price_above_sma20': 1.0,\n",
    "            'price_above_sma50': 1.0,\n",
    "            # Momentum\n",
    "            'rsi_oversold': 1.5,        # Oversold = buy opportunity\n",
    "            'rsi_overbought': -1.5,     # Overbought = sell signal\n",
    "            'macd_bullish': 1.5,\n",
    "            'roc_positive': 1.0,\n",
    "            'stoch_oversold': 1.0,\n",
    "            # Volatility/Reversion\n",
    "            'bb_oversold': 1.5,         # Mean reversion buy\n",
    "            'bb_overbought': -1.5,      # Mean reversion sell\n",
    "            'high_volatility': -0.5,    # High vol = reduce risk\n",
    "            # Volume\n",
    "            'volume_spike': 0.5,\n",
    "            'volume_confirmation': 1.5, # Price up + volume = strong\n",
    "            'volume_divergence': -1.5   # Price down + volume = weak\n",
    "        }\n",
    "        self.results = None\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        self._calculate_scores()\n",
    "        self._generate_signals()\n",
    "    \n",
    "    def _apply_by_ticker(self, func):\n",
    "        return self.data.groupby(level='ticker', group_keys=False).apply(func)\n",
    "    \n",
    "    def _calculate_scores(self):\n",
    "        self.data['rule_score'] = sum(\n",
    "            self.data[feat] * self.weights[feat] for feat in self.binary_features\n",
    "        )\n",
    "        # Normalize to [-1, 1] range\n",
    "        max_pos = sum(w for w in self.weights.values() if w > 0)\n",
    "        max_neg = abs(sum(w for w in self.weights.values() if w < 0))\n",
    "        self.data['rule_score_norm'] = self.data['rule_score'].apply(\n",
    "            lambda x: x / max_pos if x > 0 else x / max_neg if x < 0 else 0\n",
    "        )\n",
    "    \n",
    "    def _generate_signals(self):\n",
    "        # Thresholds for signal generation\n",
    "        long_threshold = 0.3\n",
    "        short_threshold = -0.3\n",
    "        \n",
    "        self.data['signal'] = 0\n",
    "        self.data.loc[self.data['rule_score_norm'] > long_threshold, 'signal'] = 1\n",
    "        self.data.loc[self.data['rule_score_norm'] < short_threshold, 'signal'] = -1\n",
    "        \n",
    "        def shift_by_ticker(df):\n",
    "            df['strategy_return'] = df['signal'].shift(1) * df['log_return']\n",
    "            return df\n",
    "        self.data = self.data.groupby(level='ticker', group_keys=False).apply(shift_by_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "11233b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up walk-forward validation with proper feature isolation...\n",
      "This will recalculate features for each fold to prevent look-ahead bias.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "WALK-FORWARD VALIDATION (Rolling Windows)\n",
      "================================================================================\n",
      "\n",
      "Fold 1:\n",
      "  Train: 2018-01-01 to 2020-01-01\n",
      "  Test:  2020-01-02 to 2020-07-02\n",
      "  Train samples: 3012, Test samples: 756\n",
      "\n",
      "Fold 2:\n",
      "  Train: 2020-01-02 to 2022-01-02\n",
      "  Test:  2022-01-03 to 2022-07-03\n",
      "  Train samples: 3024, Test samples: 744\n",
      "\n",
      "Walk-forward complete. 3 folds processed. Total test samples: 1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class XGBoostWalkForward:\n",
    "    def __init__(self, raw_data, feature_engineer_class):\n",
    "        self.raw_data = raw_data\n",
    "        self.feature_engineer_class = feature_engineer_class\n",
    "        self.all_predictions = []\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.n_estimators = 100\n",
    "        self.learning_rate = 0.1\n",
    "        self.max_depth = 3\n",
    "        self.subsample = 0.8\n",
    "        self.colsample_bytree = 0.8\n",
    "        self.threshold = 0.001\n",
    "    \n",
    "    def run_walk_forward(self, train_start='2016-01-01', test_end='2024-12-31', train_window_years=2, test_window_months=6):\n",
    "        \"\"\"Walk-forward validation with rolling window and proper feature engineering per fold\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"WALK-FORWARD VALIDATION (Rolling Windows)\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        train_start = pd.Timestamp(train_start)\n",
    "        test_end = pd.Timestamp(test_end)\n",
    "        \n",
    "        all_test_data = []\n",
    "        fold = 0\n",
    "        \n",
    "        # Rolling window approach\n",
    "        current_train_start = train_start\n",
    "        \n",
    "        while True:\n",
    "            fold += 1\n",
    "            \n",
    "            # Define train and test periods\n",
    "            current_train_end = current_train_start + pd.DateOffset(years=train_window_years)\n",
    "            current_test_start = current_train_end + pd.DateOffset(days=1)\n",
    "            current_test_end = current_test_start + pd.DateOffset(months=test_window_months)\n",
    "            \n",
    "            if current_test_end > test_end:\n",
    "                break\n",
    "            \n",
    "            print(f\"Fold {fold}:\")\n",
    "            print(f\"  Train: {current_train_start.date()} to {current_train_end.date()}\")\n",
    "            print(f\"  Test:  {current_test_start.date()} to {current_test_end.date()}\")\n",
    "            \n",
    "            # Get RAW data for this fold (up to train end for training, up to test end for testing)\n",
    "            train_raw = self.raw_data[self.raw_data.index.get_level_values('date') <= current_train_end].copy()\n",
    "            test_raw = self.raw_data[self.raw_data.index.get_level_values('date') <= current_test_end].copy()\n",
    "            \n",
    "            # Create features separately for train and test (NO LOOK-AHEAD)\n",
    "            fe_train = self.feature_engineer_class(train_raw)\n",
    "            train_features = fe_train.run_pipeline()\n",
    "            feature_cols = fe_train.finished_features\n",
    "            \n",
    "            fe_test = self.feature_engineer_class(test_raw)\n",
    "            test_features = fe_test.run_pipeline()\n",
    "            \n",
    "            # Extract actual train/test periods\n",
    "            train_mask = (train_features.index.get_level_values('date') >= current_train_start) & \\\n",
    "                        (train_features.index.get_level_values('date') <= current_train_end)\n",
    "            test_mask = (test_features.index.get_level_values('date') >= current_test_start) & \\\n",
    "                    (test_features.index.get_level_values('date') <= current_test_end)\n",
    "            \n",
    "            train_data = train_features[train_mask].dropna(subset=feature_cols + ['target'])\n",
    "            test_data = test_features[test_mask].dropna(subset=feature_cols + ['target'])\n",
    "            \n",
    "            if len(train_data) == 0 or len(test_data) == 0:\n",
    "                print(f\"  Skipping fold {fold} - insufficient data\")\n",
    "                print()\n",
    "                current_train_start = current_test_start\n",
    "                continue\n",
    "            \n",
    "            print(f\"  Train samples: {len(train_data)}, Test samples: {len(test_data)}\")\n",
    "            \n",
    "            # Train model\n",
    "            X_train = train_data[feature_cols]\n",
    "            y_train = train_data['target']\n",
    "            \n",
    "            model = xgb.XGBRegressor(\n",
    "                n_estimators=self.n_estimators,\n",
    "                learning_rate=self.learning_rate,\n",
    "                max_depth=self.max_depth,\n",
    "                subsample=self.subsample,\n",
    "                colsample_bytree=self.colsample_bytree,\n",
    "                random_state=42,\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Generate predictions on test fold\n",
    "            X_test = test_data[feature_cols]\n",
    "            test_data['xgb_pred'] = model.predict(X_test)\n",
    "            \n",
    "            # Generate signals\n",
    "            test_data['signal'] = 0\n",
    "            test_data.loc[test_data['xgb_pred'] > self.threshold, 'signal'] = 1\n",
    "            test_data.loc[test_data['xgb_pred'] < -self.threshold, 'signal'] = -1\n",
    "            \n",
    "            # Calculate returns with proper shift\n",
    "            def shift_by_ticker(df):\n",
    "                df['strategy_return'] = df['signal'].shift(1) * df['log_return']\n",
    "                return df\n",
    "            test_data = test_data.groupby(level='ticker', group_keys=False).apply(shift_by_ticker)\n",
    "            \n",
    "            all_test_data.append(test_data)\n",
    "            print()\n",
    "            \n",
    "            # Move to next window\n",
    "            current_train_start = current_test_start\n",
    "        \n",
    "        # Combine all test folds\n",
    "        self.test_data = pd.concat(all_test_data, axis=0).sort_index()\n",
    "        print(f\"Walk-forward complete. {fold} folds processed. Total test samples: {len(self.test_data)}\\n\")\n",
    "        return self.test_data\n",
    "\n",
    "# WALK-FORWARD VALIDATION WITH PROPER FEATURE ENGINEERING PER FOLD\n",
    "print(\"Setting up walk-forward validation with proper feature isolation...\")\n",
    "print(\"This will recalculate features for each fold to prevent look-ahead bias.\\n\")\n",
    "\n",
    "# XGBoost with walk-forward validation (2-year train, 6-month test windows)\n",
    "xgb_model = XGBoostWalkForward(data, FeatureEngineer)\n",
    "xgb_test_data = xgb_model.run_walk_forward(\n",
    "    train_start='2018-01-01',  # Start later to have enough feature history\n",
    "    test_end='2022-12-31',\n",
    "    train_window_years=2,\n",
    "    test_window_months=6\n",
    ")\n",
    "\n",
    "# Rule-based model on FRESH COPY of same test data (not the modified xgb version)\n",
    "# Get the original data for the same date range as xgb_test_data\n",
    "rb_test_indices = xgb_test_data.index\n",
    "base_cols = ['open', 'high', 'low', 'close', 'volume', 'log_return']\n",
    "feature_cols = [col for col in xgb_test_data.columns if col not in ['xgb_pred', 'signal', 'strategy_return']]\n",
    "rb_cols = list(dict.fromkeys(base_cols + feature_cols))\n",
    "rb_test_data = xgb_test_data[rb_cols].copy()\n",
    "rb_test_data = rb_test_data.sort_index()\n",
    "rb_test_data.index = rb_test_data.index.set_names(['ticker', 'date'])\n",
    "\n",
    "rb_model = RuleBasedModel(rb_test_data)\n",
    "rb_model.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5b4e7e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AAPL:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return           -20.92%       -5.91%      -15.00%\n",
      "  Buy & Hold                 -8.22%       -8.22%\n",
      "  Sharpe Ratio                -0.55        -0.21        -0.35\n",
      "  Max Drawdown              -36.25%      -28.07%       -8.18%\n",
      "  Win Rate                    47.3%        53.6%        -6.3%\n",
      "  Trades                        207          151           56\n",
      "\n",
      "AMZN:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return            73.67%       -5.42%       79.08%\n",
      "  Buy & Hold                 -5.47%       -5.47%\n",
      "  Sharpe Ratio                 1.23        -0.21         1.44\n",
      "  Max Drawdown              -32.12%      -21.22%      -10.90%\n",
      "  Win Rate                    47.8%        53.0%        -5.2%\n",
      "  Trades                        205          117           88\n",
      "\n",
      "GOOGL:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return            49.61%      -14.69%       64.31%\n",
      "  Buy & Hold                -20.82%      -20.82%\n",
      "  Sharpe Ratio                 1.00        -0.59         1.58\n",
      "  Max Drawdown              -29.46%      -21.53%       -7.93%\n",
      "  Win Rate                    51.5%        57.3%        -5.8%\n",
      "  Trades                        204          110           94\n",
      "\n",
      "META:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return           -20.32%      -24.36%        4.03%\n",
      "  Buy & Hold                -46.06%      -46.06%\n",
      "  Sharpe Ratio                -0.40        -0.63         0.24\n",
      "  Max Drawdown              -54.62%      -34.15%      -20.47%\n",
      "  Win Rate                    53.0%        55.8%        -2.8%\n",
      "  Trades                        215           86          129\n",
      "\n",
      "NFLX:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return           -27.12%      -37.08%        9.96%\n",
      "  Buy & Hold                -56.90%      -56.90%\n",
      "  Sharpe Ratio                -0.45        -1.22         0.77\n",
      "  Max Drawdown              -71.09%      -43.42%      -27.68%\n",
      "  Win Rate                    50.5%        44.4%         6.1%\n",
      "  Trades                        214          124           90\n",
      "\n",
      "SPY:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return            41.47%      -10.97%       52.44%\n",
      "  Buy & Hold                -23.17%      -23.17%\n",
      "  Sharpe Ratio                 0.99        -0.51         1.51\n",
      "  Max Drawdown              -38.05%      -19.10%      -18.95%\n",
      "  Win Rate                    50.0%        53.4%        -3.4%\n",
      "  Trades                        200           88          112\n",
      "\n",
      "================================================================================\n",
      "OVERALL SHARPE RATIO:\n",
      "  XGBoost:     0.175\n",
      "  Rule-Based: -0.563\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison: XGBoost vs Rule-Based\n",
    "\n",
    "def calculate_metrics(returns_col, signal_col, df, valid_indices=None):\n",
    "    \"\"\"\n",
    "    Calculate trading metrics. If valid_indices provided, use those exact rows for buy & hold.\n",
    "    This ensures both models use identical date ranges for fair comparison.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for ticker in df.index.get_level_values('ticker').unique():\n",
    "        ticker_data = df.xs(ticker, level='ticker')\n",
    "        \n",
    "        # If valid_indices provided, filter to those exact rows\n",
    "        if valid_indices is not None:\n",
    "            ticker_valid_idx = valid_indices[valid_indices.get_level_values('ticker') == ticker]\n",
    "            ticker_dates = ticker_valid_idx.get_level_values('date')\n",
    "            ticker_data = ticker_data[ticker_data.index.isin(ticker_dates)]\n",
    "        \n",
    "        # Drop rows where strategy_return is NaN (from shift operation)\n",
    "        ticker_data = ticker_data.dropna(subset=[returns_col])\n",
    "        \n",
    "        if len(ticker_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        strat_ret = ticker_data[returns_col]\n",
    "        buy_hold = ticker_data['log_return']\n",
    "        signals = ticker_data[signal_col]\n",
    "        \n",
    "        # Cumulative returns\n",
    "        strat_cum = np.exp(strat_ret.sum()) - 1\n",
    "        bh_cum = np.exp(buy_hold.sum()) - 1\n",
    "        sharpe = (strat_ret.mean() / strat_ret.std()) * np.sqrt(252) if strat_ret.std() > 0 else 0\n",
    "        \n",
    "        # Max drawdown\n",
    "        cum_log_rets = strat_ret.cumsum()\n",
    "        running_max = cum_log_rets.expanding().max()\n",
    "        drawdown = cum_log_rets - running_max\n",
    "        max_dd = np.exp(drawdown.min()) - 1\n",
    "        \n",
    "        # Win rate\n",
    "        wins = (strat_ret > 0).sum()\n",
    "        trades = (signals != 0).sum()\n",
    "        win_rate = wins / trades if trades > 0 else 0\n",
    "        \n",
    "        results[ticker] = {\n",
    "            'return': strat_cum,\n",
    "            'bh_return': bh_cum,\n",
    "            'sharpe': sharpe,\n",
    "            'max_dd': max_dd,\n",
    "            'win_rate': win_rate,\n",
    "            'trades': trades\n",
    "        }\n",
    "    all_returns = df.dropna(subset=[returns_col])[returns_col]\n",
    "    overall_sharpe = (all_returns.mean() / all_returns.std()) * np.sqrt(252) if all_returns.std() > 0 else 0\n",
    "    return results, overall_sharpe\n",
    "\n",
    "# Get the valid indices (rows without NaN) from XGBoost data\n",
    "valid_idx = xgb_test_data.dropna(subset=['strategy_return']).index\n",
    "\n",
    "# Calculate metrics using the SAME valid indices for both models\n",
    "xgb_results, xgb_overall = calculate_metrics('strategy_return', 'signal', xgb_test_data, valid_indices=valid_idx)\n",
    "rb_results, rb_overall = calculate_metrics('strategy_return', 'signal', rb_model.data, valid_indices=valid_idx)\n",
    "\n",
    "for ticker in sorted(xgb_results.keys()): #Print results in a table\n",
    "    xgb_metrics = xgb_results[ticker]\n",
    "    rb_metrics = rb_results[ticker]\n",
    "\n",
    "    print(f\"\\n{ticker}:\")\n",
    "    print(f\"  {'Metric':<20} {'XGBoost':>12} {'Rule-Based':>12} {'Difference':>12}\")\n",
    "    print(f\"  {'-'*20} {'-'*12} {'-'*12} {'-'*12}\")\n",
    "    print(f\"  {'Strategy Return':<20} {xgb_metrics['return']*100:>11.2f}% {rb_metrics['return']*100:>11.2f}% {(xgb_metrics['return']-rb_metrics['return'])*100:>11.2f}%\")\n",
    "    print(f\"  {'Buy & Hold':<20} {xgb_metrics['bh_return']*100:>11.2f}% {rb_metrics['bh_return']*100:>11.2f}%\")\n",
    "    print(f\"  {'Sharpe Ratio':<20} {xgb_metrics['sharpe']:>12.2f} {rb_metrics['sharpe']:>12.2f} {xgb_metrics['sharpe']-rb_metrics['sharpe']:>12.2f}\")\n",
    "    print(f\"  {'Max Drawdown':<20} {xgb_metrics['max_dd']*100:>11.2f}% {rb_metrics['max_dd']*100:>11.2f}% {(xgb_metrics['max_dd']-rb_metrics['max_dd'])*100:>11.2f}%\")\n",
    "    print(f\"  {'Win Rate':<20} {xgb_metrics['win_rate']*100:>11.1f}% {rb_metrics['win_rate']*100:>11.1f}% {(xgb_metrics['win_rate']-rb_metrics['win_rate'])*100:>11.1f}%\")\n",
    "    print(f\"  {'Trades':<20} {xgb_metrics['trades']:>12} {rb_metrics['trades']:>12} {xgb_metrics['trades']-rb_metrics['trades']:>12}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"OVERALL SHARPE RATIO:\")\n",
    "print(f\"  XGBoost:    {xgb_overall:>6.3f}\")\n",
    "print(f\"  Rule-Based: {rb_overall:>6.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5818be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Visualization\n",
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'SPY']\n",
    "\"\"\"continued_input = True\n",
    "while continued_input == True:\n",
    "    input_ticker = input(\"Please enter a stock ('AAPL') for example: \" )\n",
    "    for i in range(6):\n",
    "        if input_ticker == tickers[i]:\n",
    "            print(\"Done\")\n",
    "            continued_input = False\n",
    "    \n",
    "            \"\"\"\n",
    "#graphed_df = rb_model.data.xs(input_ticker, level = 0)\n",
    "\n",
    "strategy_graphed_return_pct = (np.exp(graphed_df['strategy_return'].cumsum()) - 1) * 100\n",
    "\n",
    "dates = graphed_df.index\n",
    "\n",
    "xgb_graphed_cum_return_pct = (\n",
    "    xgb_test_data\n",
    "    .groupby(level='ticker')['strategy_return']\n",
    "    .apply(lambda x: (np.exp(x.cumsum()) - 1) * 100)\n",
    ")\n",
    "\n",
    "xgb_graphed_returns = xgb_graphed_cum_return_pct.xs(input_ticker, level = 0)\n",
    "\n",
    "\n",
    "class data_analysis:\n",
    "    line_dict = dict(marker = \".\", markersize = 3)\n",
    "\n",
    "    def __init__(self, x_XGBoost, y_XGBoost, x_RB, y_RB, rb_model):\n",
    "        self.rbmodel = rb_model\n",
    "        print(\"Graphs Based on\", input_ticker, \"Stock\")\n",
    "        \n",
    "        self.xgboost_graph(x_XGBoost, y_XGBoost)\n",
    "        self.rulebased_model_graph(x_RB, y_RB)\n",
    "        self.combined_graph(x_XGBoost, y_XGBoost, x_RB, y_RB)\n",
    "\n",
    "    def xgboost_graph(self, x_XGBoost, y_XGBoost):\n",
    "        plt.title(\"XGBoost Performance Graph\")\n",
    "        \n",
    "        plt.xlabel(\"Dates\")\n",
    "        plt.ylabel(\"XGBoost Returns (%)\")\n",
    "        \n",
    "        plt.plot(dates, xgb_graphed_cum_return_pct[:len(dates)], **self.line_dict)\n",
    "        plt.tick_params(axis = 'x', which = 'major', labelsize = 8)\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "    def rulebased_model_graph(self, x_RB, y_RB):\n",
    "        plt.title(\"Rule Based Model Performance Graph\")\n",
    "\n",
    "        plt.xlabel(\"Dates\")\n",
    "        plt.ylabel(\"Rule Based Returns (%)\")\n",
    "        \n",
    "        plt.plot(dates[:len(strategy_graphed_return_pct)], strategy_graphed_return_pct, color='orange', **self.line_dict)\n",
    "        plt.tick_params(axis = 'x', which = 'major', labelsize = 8)\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "    def combined_graph(self, x_XGBoost, y_XGBoost, x_RB, y_RB):\n",
    "        plt.title(\"Combined Performance Graph\")\n",
    "\n",
    "        plt.xlabel(\"Dates\")\n",
    "        plt.ylabel(\"Strategy Returns (%)\")\n",
    "        \n",
    "        plt.plot(dates, xgb_graphed_cum_return_pct[:len(dates)], label='XGBoost', **self.line_dict)\n",
    "        plt.plot(dates[:len(strategy_graphed_return_pct)], strategy_graphed_return_pct, color='orange', label='Rule-Based', **self.line_dict)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tick_params(axis = 'x', which = 'major', labelsize = 8)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "#analyse_data = data_analysis(dates, xgb_graphed_cum_return_pct[:len(dates)], dates[:len(strategy_graphed_return_pct)], strategy_graphed_return_pct, rb_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-finance",
   "language": "python",
   "name": "conda-env-anaconda-finance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
