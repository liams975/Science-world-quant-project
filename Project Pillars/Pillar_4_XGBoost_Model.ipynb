{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2c3597b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import talib  \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tickers = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL', 'SPY']#FAANG portfolio with SPY for market proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "00fdd723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tickers have 2515 trading days\n"
     ]
    }
   ],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, tickers,):\n",
    "        self.tickers = tickers\n",
    "        self.data = None\n",
    "        \n",
    "    def run_pipeline(self, start_date='2015-01-01', end_date='2024-12-31'):\n",
    "        self._download_data(start_date, end_date)\n",
    "        self._clean_data()\n",
    "        self._validate_data()\n",
    "        return self.data\n",
    "    \n",
    "    def _download_data(self, start_date, end_date):\n",
    "        all_data = []\n",
    "        \n",
    "        for ticker in self.tickers:\n",
    "            \n",
    "            # Download with adjusted close prices and make column names lower\n",
    "            df = yf.download(ticker, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "            \n",
    "            if isinstance(df.columns, pd.MultiIndex): \n",
    "                df.columns = [col[0].lower() for col in df.columns]\n",
    "            else:\n",
    "                df.columns = [col.lower() for col in df.columns]\n",
    "            \n",
    "            df.index.names = [name.lower() if name else 'date' for name in df.index.names]\n",
    "            \n",
    "            df = df[['open', 'high', 'low', 'close', 'volume']] # Keep only essential columns\n",
    "            \n",
    "            df['ticker'] = ticker # Add ticker column and set multi-index, organize data\n",
    "            df = df.reset_index()\n",
    "            df.set_index(['ticker', 'date'], inplace=True)\n",
    "            \n",
    "            all_data.append(df)\n",
    "        \n",
    "        self.data = pd.concat(all_data, axis=0).sort_index()\n",
    "\n",
    "    def _clean_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"No data to clean!\")\n",
    "        \n",
    "        # 1. Fill small gaps (forward fill then backward fill)\n",
    "        self.data = self.data.groupby(level=0, group_keys=False).apply(lambda x: x.ffill().bfill())\n",
    "        \n",
    "        # 2. Drop any remaining NaN (usually at the beginning)\n",
    "        self.data = self.data.dropna()\n",
    "\n",
    "    def _validate_data(self):\n",
    "        # Check date alignment\n",
    "        date_counts = {}\n",
    "        for ticker in self.data.index.get_level_values(0).unique():\n",
    "            dates = self.data.xs(ticker, level=0).index\n",
    "            date_counts[ticker] = len(dates)\n",
    "        \n",
    "        if len(set(date_counts.values())) == 1:\n",
    "            print(f\"All tickers have {list(date_counts.values())[0]} trading days\")\n",
    "        else:\n",
    "            print(\"tickers have different dates\")\n",
    "\n",
    "# Create an instance and run the pipeline\n",
    "preprocessor = DataPreprocessor(tickers)\n",
    "data = preprocessor.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f31549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features created: 40\n",
      "Data shape: (15090, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>log_return</th>\n",
       "      <th>overnight_return</th>\n",
       "      <th>intraday_return</th>\n",
       "      <th>volatility_20d</th>\n",
       "      <th>atr_14</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_ratio</th>\n",
       "      <th>obv</th>\n",
       "      <th>volume_zscore</th>\n",
       "      <th>log_return_lag1</th>\n",
       "      <th>rsi_14_lag1</th>\n",
       "      <th>volume_ratio_lag1</th>\n",
       "      <th>macd_histogram_lag1</th>\n",
       "      <th>bb_position_lag1</th>\n",
       "      <th>atr_14_lag1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AAPL</th>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>24.694237</td>\n",
       "      <td>24.705322</td>\n",
       "      <td>23.798602</td>\n",
       "      <td>24.237553</td>\n",
       "      <td>212818400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212818400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>24.006988</td>\n",
       "      <td>24.086797</td>\n",
       "      <td>23.368517</td>\n",
       "      <td>23.554737</td>\n",
       "      <td>257142000</td>\n",
       "      <td>-0.028576</td>\n",
       "      <td>-0.009558</td>\n",
       "      <td>-0.019018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-44323600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>23.619027</td>\n",
       "      <td>23.816332</td>\n",
       "      <td>23.195595</td>\n",
       "      <td>23.556953</td>\n",
       "      <td>263188400</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>-0.002632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218864800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AMZN</th>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>15.629000</td>\n",
       "      <td>15.737500</td>\n",
       "      <td>15.348000</td>\n",
       "      <td>15.426000</td>\n",
       "      <td>55664000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55664000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>15.350500</td>\n",
       "      <td>15.419000</td>\n",
       "      <td>15.042500</td>\n",
       "      <td>15.109500</td>\n",
       "      <td>55484000</td>\n",
       "      <td>-0.020731</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>-0.015824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>15.112000</td>\n",
       "      <td>15.150000</td>\n",
       "      <td>14.619000</td>\n",
       "      <td>14.764500</td>\n",
       "      <td>70380000</td>\n",
       "      <td>-0.023098</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>-0.023264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70200000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GOOGL</th>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>26.430301</td>\n",
       "      <td>26.589102</td>\n",
       "      <td>26.196070</td>\n",
       "      <td>26.278946</td>\n",
       "      <td>26480000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26480000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.019238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>26.159844</td>\n",
       "      <td>26.201529</td>\n",
       "      <td>25.693369</td>\n",
       "      <td>25.778227</td>\n",
       "      <td>41182000</td>\n",
       "      <td>-0.019238</td>\n",
       "      <td>-0.004543</td>\n",
       "      <td>-0.014695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14702000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.024989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>25.829833</td>\n",
       "      <td>25.865066</td>\n",
       "      <td>25.087939</td>\n",
       "      <td>25.142031</td>\n",
       "      <td>54456000</td>\n",
       "      <td>-0.024989</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>-0.026989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-69158000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.019238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">META</th>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>78.034888</td>\n",
       "      <td>78.382458</td>\n",
       "      <td>77.160987</td>\n",
       "      <td>77.905785</td>\n",
       "      <td>18177500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18177500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>77.439077</td>\n",
       "      <td>78.700264</td>\n",
       "      <td>76.326844</td>\n",
       "      <td>76.654556</td>\n",
       "      <td>26452200</td>\n",
       "      <td>-0.016191</td>\n",
       "      <td>-0.006009</td>\n",
       "      <td>-0.010182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8274700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>76.694252</td>\n",
       "      <td>77.051748</td>\n",
       "      <td>74.837222</td>\n",
       "      <td>75.621742</td>\n",
       "      <td>27399300</td>\n",
       "      <td>-0.013565</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>-0.014083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-35674000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NFLX</th>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>4.915143</td>\n",
       "      <td>5.033143</td>\n",
       "      <td>4.873143</td>\n",
       "      <td>4.984857</td>\n",
       "      <td>134750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.052238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>4.925857</td>\n",
       "      <td>4.925857</td>\n",
       "      <td>4.714714</td>\n",
       "      <td>4.731143</td>\n",
       "      <td>181650000</td>\n",
       "      <td>-0.052238</td>\n",
       "      <td>-0.011906</td>\n",
       "      <td>-0.040331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-46900000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.017269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>4.734714</td>\n",
       "      <td>4.764000</td>\n",
       "      <td>4.566143</td>\n",
       "      <td>4.650143</td>\n",
       "      <td>160377000</td>\n",
       "      <td>-0.017269</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>-0.018023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-207277000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.052238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SPY</th>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>171.378492</td>\n",
       "      <td>171.793694</td>\n",
       "      <td>169.551596</td>\n",
       "      <td>170.589600</td>\n",
       "      <td>121465900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121465900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>169.543334</td>\n",
       "      <td>169.709412</td>\n",
       "      <td>167.201605</td>\n",
       "      <td>167.508850</td>\n",
       "      <td>169632600</td>\n",
       "      <td>-0.018224</td>\n",
       "      <td>-0.006152</td>\n",
       "      <td>-0.012072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-48166700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>167.816019</td>\n",
       "      <td>168.339177</td>\n",
       "      <td>165.133823</td>\n",
       "      <td>165.931015</td>\n",
       "      <td>209151400</td>\n",
       "      <td>-0.009464</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>-0.011296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-257318100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open        high         low       close     volume  \\\n",
       "ticker date                                                                    \n",
       "AAPL   2015-01-02   24.694237   24.705322   23.798602   24.237553  212818400   \n",
       "       2015-01-05   24.006988   24.086797   23.368517   23.554737  257142000   \n",
       "       2015-01-06   23.619027   23.816332   23.195595   23.556953  263188400   \n",
       "AMZN   2015-01-02   15.629000   15.737500   15.348000   15.426000   55664000   \n",
       "       2015-01-05   15.350500   15.419000   15.042500   15.109500   55484000   \n",
       "       2015-01-06   15.112000   15.150000   14.619000   14.764500   70380000   \n",
       "GOOGL  2015-01-02   26.430301   26.589102   26.196070   26.278946   26480000   \n",
       "       2015-01-05   26.159844   26.201529   25.693369   25.778227   41182000   \n",
       "       2015-01-06   25.829833   25.865066   25.087939   25.142031   54456000   \n",
       "META   2015-01-02   78.034888   78.382458   77.160987   77.905785   18177500   \n",
       "       2015-01-05   77.439077   78.700264   76.326844   76.654556   26452200   \n",
       "       2015-01-06   76.694252   77.051748   74.837222   75.621742   27399300   \n",
       "NFLX   2015-01-02    4.915143    5.033143    4.873143    4.984857  134750000   \n",
       "       2015-01-05    4.925857    4.925857    4.714714    4.731143  181650000   \n",
       "       2015-01-06    4.734714    4.764000    4.566143    4.650143  160377000   \n",
       "SPY    2015-01-02  171.378492  171.793694  169.551596  170.589600  121465900   \n",
       "       2015-01-05  169.543334  169.709412  167.201605  167.508850  169632600   \n",
       "       2015-01-06  167.816019  168.339177  165.133823  165.931015  209151400   \n",
       "\n",
       "                   log_return  overnight_return  intraday_return  \\\n",
       "ticker date                                                        \n",
       "AAPL   2015-01-02         NaN               NaN        -0.018667   \n",
       "       2015-01-05   -0.028576         -0.009558        -0.019018   \n",
       "       2015-01-06    0.000094          0.002726        -0.002632   \n",
       "AMZN   2015-01-02         NaN               NaN        -0.013074   \n",
       "       2015-01-05   -0.020731         -0.004906        -0.015824   \n",
       "       2015-01-06   -0.023098          0.000165        -0.023264   \n",
       "GOOGL  2015-01-02         NaN               NaN        -0.005743   \n",
       "       2015-01-05   -0.019238         -0.004543        -0.014695   \n",
       "       2015-01-06   -0.024989          0.002000        -0.026989   \n",
       "META   2015-01-02         NaN               NaN        -0.001656   \n",
       "       2015-01-05   -0.016191         -0.006009        -0.010182   \n",
       "       2015-01-06   -0.013565          0.000518        -0.014083   \n",
       "NFLX   2015-01-02         NaN               NaN         0.014084   \n",
       "       2015-01-05   -0.052238         -0.011906        -0.040331   \n",
       "       2015-01-06   -0.017269          0.000755        -0.018023   \n",
       "SPY    2015-01-02         NaN               NaN        -0.004614   \n",
       "       2015-01-05   -0.018224         -0.006152        -0.012072   \n",
       "       2015-01-06   -0.009464          0.001832        -0.011296   \n",
       "\n",
       "                   volatility_20d  atr_14  ...  volume_ratio          obv  \\\n",
       "ticker date                                ...                              \n",
       "AAPL   2015-01-02             NaN     NaN  ...           NaN  212818400.0   \n",
       "       2015-01-05             NaN     NaN  ...           NaN  -44323600.0   \n",
       "       2015-01-06             NaN     NaN  ...           NaN  218864800.0   \n",
       "AMZN   2015-01-02             NaN     NaN  ...           NaN   55664000.0   \n",
       "       2015-01-05             NaN     NaN  ...           NaN     180000.0   \n",
       "       2015-01-06             NaN     NaN  ...           NaN  -70200000.0   \n",
       "GOOGL  2015-01-02             NaN     NaN  ...           NaN   26480000.0   \n",
       "       2015-01-05             NaN     NaN  ...           NaN  -14702000.0   \n",
       "       2015-01-06             NaN     NaN  ...           NaN  -69158000.0   \n",
       "META   2015-01-02             NaN     NaN  ...           NaN   18177500.0   \n",
       "       2015-01-05             NaN     NaN  ...           NaN   -8274700.0   \n",
       "       2015-01-06             NaN     NaN  ...           NaN  -35674000.0   \n",
       "NFLX   2015-01-02             NaN     NaN  ...           NaN  134750000.0   \n",
       "       2015-01-05             NaN     NaN  ...           NaN  -46900000.0   \n",
       "       2015-01-06             NaN     NaN  ...           NaN -207277000.0   \n",
       "SPY    2015-01-02             NaN     NaN  ...           NaN  121465900.0   \n",
       "       2015-01-05             NaN     NaN  ...           NaN  -48166700.0   \n",
       "       2015-01-06             NaN     NaN  ...           NaN -257318100.0   \n",
       "\n",
       "                   volume_zscore  log_return_lag1  rsi_14_lag1  \\\n",
       "ticker date                                                      \n",
       "AAPL   2015-01-02            NaN              NaN          NaN   \n",
       "       2015-01-05            NaN              NaN          NaN   \n",
       "       2015-01-06            NaN        -0.028576          NaN   \n",
       "AMZN   2015-01-02            NaN              NaN          NaN   \n",
       "       2015-01-05            NaN              NaN          NaN   \n",
       "       2015-01-06            NaN        -0.020731          NaN   \n",
       "GOOGL  2015-01-02            NaN              NaN          NaN   \n",
       "       2015-01-05            NaN              NaN          NaN   \n",
       "       2015-01-06            NaN        -0.019238          NaN   \n",
       "META   2015-01-02            NaN              NaN          NaN   \n",
       "       2015-01-05            NaN              NaN          NaN   \n",
       "       2015-01-06            NaN        -0.016191          NaN   \n",
       "NFLX   2015-01-02            NaN              NaN          NaN   \n",
       "       2015-01-05            NaN              NaN          NaN   \n",
       "       2015-01-06            NaN        -0.052238          NaN   \n",
       "SPY    2015-01-02            NaN              NaN          NaN   \n",
       "       2015-01-05            NaN              NaN          NaN   \n",
       "       2015-01-06            NaN        -0.018224          NaN   \n",
       "\n",
       "                   volume_ratio_lag1  macd_histogram_lag1  bb_position_lag1  \\\n",
       "ticker date                                                                   \n",
       "AAPL   2015-01-02                NaN                  NaN               NaN   \n",
       "       2015-01-05                NaN                  NaN               NaN   \n",
       "       2015-01-06                NaN                  NaN               NaN   \n",
       "AMZN   2015-01-02                NaN                  NaN               NaN   \n",
       "       2015-01-05                NaN                  NaN               NaN   \n",
       "       2015-01-06                NaN                  NaN               NaN   \n",
       "GOOGL  2015-01-02                NaN                  NaN               NaN   \n",
       "       2015-01-05                NaN                  NaN               NaN   \n",
       "       2015-01-06                NaN                  NaN               NaN   \n",
       "META   2015-01-02                NaN                  NaN               NaN   \n",
       "       2015-01-05                NaN                  NaN               NaN   \n",
       "       2015-01-06                NaN                  NaN               NaN   \n",
       "NFLX   2015-01-02                NaN                  NaN               NaN   \n",
       "       2015-01-05                NaN                  NaN               NaN   \n",
       "       2015-01-06                NaN                  NaN               NaN   \n",
       "SPY    2015-01-02                NaN                  NaN               NaN   \n",
       "       2015-01-05                NaN                  NaN               NaN   \n",
       "       2015-01-06                NaN                  NaN               NaN   \n",
       "\n",
       "                   atr_14_lag1    target  \n",
       "ticker date                               \n",
       "AAPL   2015-01-02          NaN -0.028576  \n",
       "       2015-01-05          NaN  0.000094  \n",
       "       2015-01-06          NaN  0.013925  \n",
       "AMZN   2015-01-02          NaN -0.020731  \n",
       "       2015-01-05          NaN -0.023098  \n",
       "       2015-01-06          NaN  0.010544  \n",
       "GOOGL  2015-01-02          NaN -0.019238  \n",
       "       2015-01-05          NaN -0.024989  \n",
       "       2015-01-06          NaN -0.002945  \n",
       "META   2015-01-02          NaN -0.016191  \n",
       "       2015-01-05          NaN -0.013565  \n",
       "       2015-01-06          NaN  0.000000  \n",
       "NFLX   2015-01-02          NaN -0.052238  \n",
       "       2015-01-05          NaN -0.017269  \n",
       "       2015-01-06          NaN  0.005178  \n",
       "SPY    2015-01-02          NaN -0.018224  \n",
       "       2015-01-05          NaN -0.009464  \n",
       "       2015-01-06          NaN  0.012384  \n",
       "\n",
       "[18 rows x 46 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureEngineer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.finished_features = []\n",
    "        \n",
    "    def run_pipeline(self):\n",
    "        self.core_price_features()\n",
    "        self.math_rule_features()\n",
    "        self.momentum_features()\n",
    "        self.volatility_features()\n",
    "        self.volume_features()\n",
    "        self.lagged_features()\n",
    "        self.target_variable()\n",
    "        return self.data\n",
    "    \n",
    "    def _apply_by_ticker(self, func):\n",
    "        return self.data.groupby(level='ticker', group_keys=False).apply(func)\n",
    "    \n",
    "    def core_price_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low, open_ = df['close'], df['high'], df['low'], df['open']\n",
    "            \n",
    "            # Returns\n",
    "            df['log_return'] = np.log(close / close.shift(1))\n",
    "            df['overnight_return'] = np.log(open_ / close.shift(1))\n",
    "            df['intraday_return'] = np.log(close / open_)\n",
    "            # Volatility\n",
    "            df['volatility_20d'] = df['log_return'].rolling(20).std() * np.sqrt(252)\n",
    "            df['atr_14'] = talib.ATR(high, low, close, timeperiod=14)\n",
    "            # SMAs\n",
    "            sma10 = talib.SMA(close, timeperiod=10)\n",
    "            sma20 = talib.SMA(close, timeperiod=20)\n",
    "            sma50 = talib.SMA(close, timeperiod=50)\n",
    "            #ratios\n",
    "            df['price_sma20_ratio'] = close / sma20\n",
    "            df['price_sma50_ratio'] = close / sma50\n",
    "            df['sma10_sma20_ratio'] = sma10 / sma20\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['log_return', 'overnight_return', 'intraday_return', 'volatility_20d', 'atr_14', 'price_sma20_ratio', 'price_sma50_ratio', 'sma10_sma20_ratio']\n",
    "    \n",
    "    def math_rule_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low, volume = df['close'], df['high'], df['low'], df['volume']\n",
    "            \n",
    "            # SMAs\n",
    "            sma10 = talib.SMA(close, timeperiod=10)\n",
    "            sma20 = talib.SMA(close, timeperiod=20)\n",
    "            sma50 = talib.SMA(close, timeperiod=50)\n",
    "            sma200 = talib.SMA(close, timeperiod=200)\n",
    "            \n",
    "            # Trends\n",
    "            df['golden_cross'] = (sma50 > sma200).astype(int)\n",
    "            df['short_uptrend'] = (sma10 > sma20).astype(int)\n",
    "            df['price_above_sma20'] = (close > sma20).astype(int)\n",
    "            df['price_above_sma50'] = (close > sma50).astype(int)\n",
    "            \n",
    "            # Momentum\n",
    "            rsi = talib.RSI(close, timeperiod=14)\n",
    "            macd, signal, _ = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            stoch_k, _ = talib.STOCH(high, low, close, fastk_period=14, slowk_period=3, slowd_period=3)\n",
    "            roc = talib.ROC(close, timeperiod=10)\n",
    "            df['rsi_oversold'] = (rsi < 30).astype(int)\n",
    "            df['rsi_overbought'] = (rsi > 70).astype(int)\n",
    "            df['macd_bullish'] = (macd > signal).astype(int)\n",
    "            df['roc_positive'] = (roc > 0).astype(int)\n",
    "            df['stoch_oversold'] = (stoch_k < 20).astype(int)\n",
    "            \n",
    "            # Volatility/Reversion \n",
    "            upper, _, lower = talib.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "            bb_pos = (close - lower) / (upper - lower)\n",
    "            vol_20d = df['log_return'].rolling(20).std() * np.sqrt(252)\n",
    "            vol_75pct = vol_20d.expanding().quantile(0.75)\n",
    "            df['bb_oversold'] = (bb_pos < 0.2).astype(int)\n",
    "            df['bb_overbought'] = (bb_pos > 0.8).astype(int)\n",
    "            df['high_volatility'] = (vol_20d > vol_75pct).astype(int)\n",
    "            \n",
    "            # Volume \n",
    "            vol_sma20 = talib.SMA(volume, timeperiod=20)\n",
    "            vol_ratio = volume / vol_sma20\n",
    "            price_up = close > close.shift(1)\n",
    "            price_down = close < close.shift(1)\n",
    "            df['volume_spike'] = (vol_ratio > 1.5).astype(int)\n",
    "            df['volume_confirmation'] = (price_up & (vol_ratio > 1)).astype(int)\n",
    "            df['volume_divergence'] = (price_down & (vol_ratio > 1)).astype(int)\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['golden_cross', 'short_uptrend', 'price_above_sma20', 'price_above_sma50','rsi_oversold', 'rsi_overbought', 'macd_bullish', 'roc_positive', 'stoch_oversold','bb_oversold', 'bb_overbought', 'high_volatility','volume_spike', 'volume_confirmation', 'volume_divergence']\n",
    "    \n",
    "    def momentum_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low = df['close'], df['high'], df['low']\n",
    "            \n",
    "            df['rsi_14'] = talib.RSI(close, timeperiod=14)\n",
    "            macd, signal, hist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "            df['macd_histogram'] = hist\n",
    "            df['stoch_k'], _ = talib.STOCH(high, low, close, fastk_period=14, slowk_period=3, slowd_period=3)\n",
    "            df['williams_r'] = talib.WILLR(high, low, close, timeperiod=14)\n",
    "            df['roc_10'] = talib.ROC(close, timeperiod=10)\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['rsi_14', 'macd_histogram', 'stoch_k', 'williams_r', 'roc_10']\n",
    "    \n",
    "    def volatility_features(self):\n",
    "        def calc(df):\n",
    "            close, high, low = df['close'], df['high'], df['low']\n",
    "            \n",
    "            # Bollinger Bands\n",
    "            upper, middle, lower = talib.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "            df['bb_position'] = (close - lower) / (upper - lower)\n",
    "            df['bb_width'] = (upper - lower) / middle\n",
    "            \n",
    "            # Parkinson volatility (high-low based)\n",
    "            df['parkinson_vol'] = np.sqrt((1 / (4 * np.log(2))) * (np.log(high / low) ** 2)).rolling(20).mean()\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['bb_position', 'bb_width', 'parkinson_vol',]\n",
    "    \n",
    "    def volume_features(self):\n",
    "        def calc(df):\n",
    "            close, volume = df['close'], df['volume']\n",
    "            \n",
    "            vol_sma20 = talib.SMA(volume, timeperiod=20)\n",
    "            df['volume_ratio'] = volume / vol_sma20\n",
    "            df['obv'] = talib.OBV(close, volume)\n",
    "            df['volume_zscore'] = (volume - volume.rolling(20).mean()) / volume.rolling(20).std()\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += ['volume_ratio', 'obv', 'volume_zscore']\n",
    "    \n",
    "    def lagged_features(self):\n",
    "        lag_cols = ['log_return', 'rsi_14', 'volume_ratio', 'macd_histogram', 'bb_position', 'atr_14']\n",
    "        \n",
    "        def calc(df):\n",
    "            for col in lag_cols:\n",
    "                df[f'{col}_lag1'] = df[col].shift(1)\n",
    "            return df\n",
    "        \n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "        self.finished_features += [f'{col}_lag1' for col in lag_cols]\n",
    "    \n",
    "    def target_variable(self):\n",
    "        def calc(df):\n",
    "            df['target'] = df['log_return'].shift(-1)  # Predict tomorrow's return\n",
    "            return df\n",
    "        self.data = self._apply_by_ticker(calc)\n",
    "\n",
    "# Run the feature engineering pipeline\n",
    "fe = FeatureEngineer(data)\n",
    "features_data = fe.run_pipeline()\n",
    "\n",
    "print(f\"Features created: {len(fe.finished_features)}\")\n",
    "print(f\"Data shape: {features_data.shape}\")\n",
    "features_data.groupby(level='ticker').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedModel:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.binary_features = [\n",
    "            'golden_cross', 'short_uptrend', 'price_above_sma20', 'price_above_sma50','rsi_oversold', 'rsi_overbought', 'macd_bullish', 'roc_positive',\n",
    "            'stoch_oversold','bb_oversold', 'bb_overbought', 'high_volatility','volume_spike', 'volume_confirmation', 'volume_divergence'\n",
    "        ]\n",
    "        # Default weights: positive = bullish signal, negative = bearish signal\n",
    "        self.weights = {\n",
    "            # Trend (bullish)\n",
    "            'golden_cross': 2.0,\n",
    "            'short_uptrend': 1.5,\n",
    "            'price_above_sma20': 1.0,\n",
    "            'price_above_sma50': 1.0,\n",
    "            # Momentum\n",
    "            'rsi_oversold': 1.5,        # Oversold = buy opportunity\n",
    "            'rsi_overbought': -1.5,     # Overbought = sell signal\n",
    "            'macd_bullish': 1.5,\n",
    "            'roc_positive': 1.0,\n",
    "            'stoch_oversold': 1.0,\n",
    "            # Volatility/Reversion\n",
    "            'bb_oversold': 1.5,         # Mean reversion buy\n",
    "            'bb_overbought': -1.5,      # Mean reversion sell\n",
    "            'high_volatility': -0.5,    # High vol = reduce risk\n",
    "            # Volume\n",
    "            'volume_spike': 0.5,\n",
    "            'volume_confirmation': 1.5, # Price up + volume = strong\n",
    "            'volume_divergence': -1.5   # Price down + volume = weak\n",
    "        }\n",
    "        self.results = None\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        self._calculate_scores()\n",
    "        self._generate_signals()\n",
    "        self._evaluate_performance()\n",
    "    \n",
    "    def _apply_by_ticker(self, func):\n",
    "        return self.data.groupby(level='ticker', group_keys=False).apply(func)\n",
    "    \n",
    "    def _calculate_scores(self):\n",
    "        self.data['rule_score'] = sum(\n",
    "            self.data[feat] * self.weights[feat] for feat in self.binary_features\n",
    "        )\n",
    "        # Normalize to [-1, 1] range\n",
    "        max_pos = sum(w for w in self.weights.values() if w > 0)\n",
    "        max_neg = abs(sum(w for w in self.weights.values() if w < 0))\n",
    "        self.data['rule_score_norm'] = self.data['rule_score'].apply(\n",
    "            lambda x: x / max_pos if x > 0 else x / max_neg if x < 0 else 0\n",
    "        )\n",
    "    \n",
    "    def _generate_signals(self):\n",
    "        # Thresholds for signal generation\n",
    "        long_threshold = 0.3\n",
    "        short_threshold = -0.3\n",
    "        \n",
    "        self.data['signal'] = 0\n",
    "        self.data.loc[self.data['rule_score_norm'] > long_threshold, 'signal'] = 1\n",
    "        self.data.loc[self.data['rule_score_norm'] < short_threshold, 'signal'] = -1\n",
    "        \n",
    "        # Strategy return: shift signal to simulate real trading (signal today → trade tomorrow)\n",
    "        self.data['strategy_return'] = self.data['signal'].shift(1) * self.data['log_return']\n",
    "    \n",
    "    def _evaluate_performance(self):\n",
    "        def calc_metrics(df):\n",
    "            df = df.dropna(subset=['strategy_return', 'log_return'])\n",
    "            if len(df) == 0:\n",
    "                return pd.Series()\n",
    "            \n",
    "            strat_ret = df['strategy_return']\n",
    "            buy_hold = df['log_return']  # Use actual returns, not shifted target\n",
    "            trading_days = 252\n",
    "            \n",
    "            # Cumulative returns - FIXED: Use exp(sum) for log returns\n",
    "            strat_cum = np.exp(strat_ret.sum()) - 1\n",
    "            bh_cum = np.exp(buy_hold.sum()) - 1\n",
    "            \n",
    "            # Sharpe ratio (annualized)\n",
    "            sharpe = (strat_ret.mean() / strat_ret.std()) * np.sqrt(trading_days) if strat_ret.std() > 0 else 0\n",
    "            \n",
    "            # Max drawdown - FIXED: Use log space\n",
    "            cum_log_rets = strat_ret.cumsum()\n",
    "            running_max = cum_log_rets.expanding().max()\n",
    "            drawdown = cum_log_rets - running_max\n",
    "            max_dd = np.exp(drawdown.min()) - 1\n",
    "            \n",
    "            # Win rate\n",
    "            wins = (strat_ret > 0).sum()\n",
    "            total_trades = (df['signal'] != 0).sum()\n",
    "            win_rate = wins / total_trades if total_trades > 0 else 0\n",
    "            \n",
    "            return pd.Series({\n",
    "                'total_return': strat_cum,\n",
    "                'buy_hold_return': bh_cum,\n",
    "                'sharpe_ratio': sharpe,\n",
    "                'max_drawdown': max_dd,\n",
    "                'win_rate': win_rate,\n",
    "                'n_trades': total_trades,\n",
    "                'n_days': len(df)\n",
    "            })\n",
    "        \n",
    "        # Per-ticker results\n",
    "        self.results = self.data.groupby(level='ticker').apply(calc_metrics)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"=\" * 60)\n",
    "        print(\"RULE-BASED MODEL PERFORMANCE\")\n",
    "        print(\"=\" * 60)\n",
    "        for ticker in self.results.index:\n",
    "            r = self.results.loc[ticker]\n",
    "            print(f\"\\n{ticker}:\")\n",
    "            print(f\"  Strategy Return: {r['total_return']*100:>8.2f}%  |  Buy & Hold: {r['buy_hold_return']*100:>8.2f}%\")\n",
    "            print(f\"  Sharpe Ratio:    {r['sharpe_ratio']:>8.2f}   |  Max Drawdown: {r['max_drawdown']*100:>7.2f}%\")\n",
    "            print(f\"  Win Rate:        {r['win_rate']*100:>8.1f}%  |  Trades: {int(r['n_trades'])}\")\n",
    "        \n",
    "        # Overall\n",
    "        overall = self.data.dropna(subset=['strategy_return'])\n",
    "        overall_sharpe = (overall['strategy_return'].mean() / overall['strategy_return'].std()) * np.sqrt(252)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"OVERALL SHARPE: {overall_sharpe:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "afbf7e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AAPL:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return           156.52%       70.57%       85.95%\n",
      "  Buy & Hold                 75.63%       75.63%\n",
      "  Sharpe Ratio                 1.88         1.09         0.79\n",
      "  Max Drawdown              -20.87%      -29.21%        8.35%\n",
      "  Win Rate                    56.6%        54.4%         2.2%\n",
      "  Trades                        442          443           -1\n",
      "\n",
      "AMZN:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return            50.56%       54.79%       -4.23%\n",
      "  Buy & Hold                 58.01%       58.01%\n",
      "  Sharpe Ratio                 0.71         0.83        -0.12\n",
      "  Max Drawdown              -32.03%      -26.16%       -5.87%\n",
      "  Win Rate                    54.0%        56.1%        -2.1%\n",
      "  Trades                        417          426           -9\n",
      "\n",
      "GOOGL:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return           153.48%       25.33%      128.14%\n",
      "  Buy & Hold                 27.15%       27.15%\n",
      "  Sharpe Ratio                 1.93         0.49         1.43\n",
      "  Max Drawdown              -18.98%      -18.57%       -0.41%\n",
      "  Win Rate                    54.5%        52.2%         2.3%\n",
      "  Trades                        422          425           -3\n",
      "\n",
      "META:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return            99.77%       20.14%       79.62%\n",
      "  Buy & Hold                 16.32%       16.32%\n",
      "  Sharpe Ratio                 1.10         0.32         0.77\n",
      "  Max Drawdown              -15.68%      -33.86%       18.19%\n",
      "  Win Rate                    52.6%        52.5%         0.0%\n",
      "  Trades                        409          377           32\n",
      "\n",
      "NFLX:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return           115.15%       28.98%       86.17%\n",
      "  Buy & Hold                 68.56%       68.56%\n",
      "  Sharpe Ratio                 0.97         0.34         0.63\n",
      "  Max Drawdown              -25.83%      -43.84%       18.01%\n",
      "  Win Rate                    52.3%        50.4%         1.9%\n",
      "  Trades                        453          407           46\n",
      "\n",
      "SPY:\n",
      "  Metric                    XGBoost   Rule-Based   Difference\n",
      "  -------------------- ------------ ------------ ------------\n",
      "  Strategy Return            26.34%       25.06%        1.29%\n",
      "  Buy & Hold                 25.23%       25.23%\n",
      "  Sharpe Ratio                 0.89         0.89        -0.01\n",
      "  Max Drawdown              -10.13%      -10.70%        0.57%\n",
      "  Win Rate                    55.6%        57.0%        -1.5%\n",
      "  Trades                        414          442          -28\n",
      "\n",
      "================================================================================\n",
      "OVERALL SHARPE RATIO:\n",
      "  XGBoost:     1.177\n",
      "  Rule-Based:  0.587\n",
      "  Difference:  0.590\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get feature columns (exclude target and original OHLCV columns)\n",
    "feature_cols = fe.finished_features\n",
    "model_df = features_data.dropna(subset=feature_cols + ['target']).copy()\n",
    "\n",
    "# EXPERIMENT: Train on bull market (2020-2023), Test on volatile period (2018-2020 with COVID)\n",
    "# This reverses the regime to see how models handle crisis vs trend-following\n",
    "dates = model_df.index.get_level_values('date').unique().sort_values()\n",
    "\n",
    "# Define specific periods\n",
    "train_start = pd.Timestamp('2020-01-01')\n",
    "train_end = pd.Timestamp('2023-01-12')  # Train on 2020-2023 (recovery + bull)\n",
    "test_start = pd.Timestamp('2018-01-01') \n",
    "test_end = pd.Timestamp('2020-01-01')   # Test on 2018-2020 (includes COVID crash)\n",
    "\n",
    "train_mask = (model_df.index.get_level_values('date') >= train_start) & \\\n",
    "            (model_df.index.get_level_values('date') <= train_end)\n",
    "test_mask = (model_df.index.get_level_values('date') >= test_start) & \\\n",
    "            (model_df.index.get_level_values('date') < test_end)\n",
    "\n",
    "P_train = model_df.loc[train_mask, feature_cols]\n",
    "P_test = model_df.loc[test_mask, feature_cols]\n",
    "H_train = model_df.loc[train_mask, 'target']\n",
    "H_test = model_df.loc[test_mask, 'target']\n",
    "\n",
    "# Train XGBoost Regressor with simpler, more robust hyperparameters\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "model.fit(P_train, H_train)\n",
    "preds = model.predict(P_test)\n",
    "\n",
    "# Generate signals on test data\n",
    "test_data = model_df[test_mask].copy()\n",
    "test_data['xgb_pred'] = preds\n",
    "\n",
    "# Signal generation with reasonable threshold\n",
    "threshold = 0.0005  # 0.05% daily return threshold\n",
    "test_data['xgb_signal'] = 0\n",
    "test_data.loc[test_data['xgb_pred'] > threshold, 'xgb_signal'] = 1\n",
    "test_data.loc[test_data['xgb_pred'] < -threshold, 'xgb_signal'] = -1\n",
    "\n",
    "# Shift signal forward to simulate real trading: signal today → trade tomorrow\n",
    "test_data['xgb_return'] = test_data['xgb_signal'].shift(1) * test_data['log_return']\n",
    "\n",
    "\n",
    "rb_test = RuleBasedModel(test_data)\n",
    "rb_test._calculate_scores()\n",
    "rb_test._generate_signals()\n",
    "test_data['rb_signal'] = rb_test.data['signal']\n",
    "test_data['rb_return'] = rb_test.data['strategy_return']\n",
    "\n",
    "\n",
    "def calculate_metrics(returns_col, signal_col, df):\n",
    "    results = {}\n",
    "    for ticker in df.index.get_level_values('ticker').unique():\n",
    "        ticker_data = df.xs(ticker, level='ticker').dropna(subset=[returns_col, 'log_return'])\n",
    "        if len(ticker_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        strat_ret = ticker_data[returns_col]\n",
    "        buy_hold = ticker_data['log_return']  # Use actual returns, not shifted target\n",
    "        signals = ticker_data[signal_col]\n",
    "\n",
    "        # CRITICAL FIX: Use exp(sum(log_returns)) for proper compounding\n",
    "        strat_cum = np.exp(strat_ret.sum()) - 1\n",
    "        bh_cum = np.exp(buy_hold.sum()) - 1\n",
    "        sharpe = (strat_ret.mean() / strat_ret.std()) * np.sqrt(252) if strat_ret.std() > 0 else 0\n",
    "        \n",
    "        # Max drawdown using log returns\n",
    "        cum_log_rets = strat_ret.cumsum()\n",
    "        running_max = cum_log_rets.expanding().max()\n",
    "        drawdown = cum_log_rets - running_max\n",
    "        max_dd = np.exp(drawdown.min()) - 1\n",
    "        \n",
    "        wins = (strat_ret > 0).sum()\n",
    "        trades = (signals != 0).sum()\n",
    "        win_rate = wins / trades if trades > 0 else 0\n",
    "\n",
    "        results[ticker] = {\n",
    "            'return': strat_cum,\n",
    "            'bh_return': bh_cum,\n",
    "            'sharpe': sharpe,\n",
    "            'max_dd': max_dd,\n",
    "            'win_rate': win_rate,\n",
    "            'trades': trades\n",
    "        }\n",
    "\n",
    "    all_returns = df.dropna(subset=[returns_col])[returns_col]\n",
    "    overall_sharpe = (all_returns.mean() / all_returns.std()) * np.sqrt(252) if all_returns.std() > 0 else 0\n",
    "\n",
    "    return results, overall_sharpe\n",
    "\n",
    "\n",
    "xgb_results, xgb_overall = calculate_metrics('xgb_return', 'xgb_signal', test_data)\n",
    "rb_results, rb_overall = calculate_metrics('rb_return', 'rb_signal', test_data)\n",
    "\n",
    "for ticker in sorted(xgb_results.keys()):\n",
    "    xgb_metrics = xgb_results[ticker]\n",
    "    rb_metrics = rb_results[ticker]\n",
    "\n",
    "    print(f\"\\n{ticker}:\")\n",
    "    print(f\"  {'Metric':<20} {'XGBoost':>12} {'Rule-Based':>12} {'Difference':>12}\")\n",
    "    print(f\"  {'-'*20} {'-'*12} {'-'*12} {'-'*12}\")\n",
    "    print(f\"  {'Strategy Return':<20} {xgb_metrics['return']*100:>11.2f}% {rb_metrics['return']*100:>11.2f}% {(xgb_metrics['return']-rb_metrics['return'])*100:>11.2f}%\")\n",
    "    print(f\"  {'Buy & Hold':<20} {xgb_metrics['bh_return']*100:>11.2f}% {rb_metrics['bh_return']*100:>11.2f}%\")\n",
    "    print(f\"  {'Sharpe Ratio':<20} {xgb_metrics['sharpe']:>12.2f} {rb_metrics['sharpe']:>12.2f} {xgb_metrics['sharpe']-rb_metrics['sharpe']:>12.2f}\")\n",
    "    print(f\"  {'Max Drawdown':<20} {xgb_metrics['max_dd']*100:>11.2f}% {rb_metrics['max_dd']*100:>11.2f}% {(xgb_metrics['max_dd']-rb_metrics['max_dd'])*100:>11.2f}%\")\n",
    "    print(f\"  {'Win Rate':<20} {xgb_metrics['win_rate']*100:>11.1f}% {rb_metrics['win_rate']*100:>11.1f}% {(xgb_metrics['win_rate']-rb_metrics['win_rate'])*100:>11.1f}%\")\n",
    "    print(f\"  {'Trades':<20} {xgb_metrics['trades']:>12} {rb_metrics['trades']:>12} {xgb_metrics['trades']-rb_metrics['trades']:>12}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"OVERALL SHARPE RATIO:\")\n",
    "print(f\"  XGBoost:    {xgb_overall:>6.3f}\")\n",
    "print(f\"  Rule-Based: {rb_overall:>6.3f}\")\n",
    "print(f\"  Difference: {xgb_overall - rb_overall:>6.3f}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-finance",
   "language": "python",
   "name": "conda-env-anaconda-finance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
